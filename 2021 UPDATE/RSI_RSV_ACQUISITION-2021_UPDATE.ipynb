{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPORTANT NOTEBOOK FOR REPO X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import csv\n",
    "import search\n",
    "import simulate_keywords\n",
    "from google_client import GoogleClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRENDS_DEVELOPER_KEY=''\n"
     ]
    }
   ],
   "source": [
    " # !!! Remove before uploading code\n",
    "%env TRENDS_DEVELOPER_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control your initial search terms which you would like to run the simulation for here\n",
    "initial_search_terms = ['over the counter pill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geolocations(): \n",
    "    locations = []\n",
    "    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader: \n",
    "            code = row[\"geo_code\"]\n",
    "            description = row[\"description\"]\n",
    "            locations.append({\"code\": code, \"description\": description})\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate master list of top queries for all geolocations during the specified time period\n",
    "Get relative search volume of top queries for initial search term\n",
    "\"\"\"\n",
    "def run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n",
    "    master_list = set()\n",
    "    relative_search_volumes = dict()\n",
    "    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n",
    "    top_queries_relative_search_index = dict()\n",
    "    for loc in load_geolocations(): \n",
    "        \n",
    "        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n",
    "        simulation.generate_keywords()\n",
    "        simulation.get_relative_search_volumes()\n",
    "        simulation.generate_simulation_csvs()\n",
    "        level_queries = {}\n",
    "        queryLevel = 1\n",
    "        \"\"\"//**for level in simulation.initial_queries['level']:\n",
    "            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n",
    "            top_queries[level] = top_queries_in_level\n",
    "            for query in top_queries_in_level:\n",
    "                master_list.add(query)\n",
    "                if (queryLevel not in level_queries.keys()):\n",
    "                    level_queries[queryLevel] = [query]\n",
    "                else:\n",
    "                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n",
    "            queryLevel +=1\n",
    "        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n",
    "                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n",
    "                              endDateTimelines='2020-08-01'))*//\"\"\"\n",
    "        \n",
    "        #print(simulation.initial_queries)   \n",
    "        \n",
    "        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n",
    "        top_queries = [q['query'] for q in simulation.initial_queries]\n",
    "        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n",
    "        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n",
    "        for query in top_queries: \n",
    "             master_list.add(query)\n",
    "        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n",
    "        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n",
    "    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ashley Kong October 18, 2020\n",
    "# remove duplicate relevant search terms \n",
    "# and return list of dictionaries of \n",
    "# unique queries and their respective relevant serach indices\n",
    "def remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n",
    "                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n",
    "    unique_queries = {}\n",
    "    for dictionary in list_of_dictionaries:\n",
    "        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n",
    "        if query not in running_log_of_relevant_terms_list:\n",
    "            running_log_of_relevant_terms_list.append(query)\n",
    "            unique_queries[query] = dictionary[query]\n",
    "    unique_queries = restandardize_rsi(unique_queries)\n",
    "    return unique_queries\n",
    "\n",
    "# Ashley Kong November 17, 2020\n",
    "# Restandardize the relative search index\n",
    "# after obtaining unique list of relevant search terms\n",
    "# for a given initial search term(can be a term from a specific level)\n",
    "\n",
    "def restandardize_rsi(unique_queries_dict): \n",
    "                    # {abortion pill: ###, etc.}\n",
    "    total = sum([item for item in list(unique_queries_dict.values())])\n",
    "    for query in list(unique_queries_dict.keys()):\n",
    "        unique_queries_dict[query] = unique_queries_dict[query]/ total\n",
    "    return unique_queries_dict\n",
    "\n",
    "\n",
    "# Ashley Kong November 17, 2020\n",
    "# Running log of all levels and terms in a single iteration\n",
    "def add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n",
    "                # ex. 1, 'abortion pill', ('abortion': ###)\n",
    "                # origin_initial_term will give us the previous term\n",
    "                # that the new level relevant search terms are for\n",
    "    \n",
    "    level_dict = {}\n",
    "    #check if the level exists in level_log\n",
    "    if new_level in list(level_log.keys()):\n",
    "        level_dict = level_log[new_level] #ex. level_log[1] --> \n",
    "                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n",
    "    level_dict[origin_initial_term] = dictionary_rsi_terms\n",
    "    level_log[new_level] = level_dict\n",
    "    return level_log\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run the simulation for all initial search terms \n",
    "Generates a dictionary mapping initial_search_term to its master list for all locations\n",
    "Generates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n",
    "\"\"\"\n",
    "all_master_lists = dict()\n",
    "all_relative_search_volumes = dict()\n",
    "all_top_queries_rsi = dict()\n",
    "lst_initial_queries = []\n",
    "for initial_search_term in initial_search_terms: \n",
    "    # Note: must specify explicit startDate & endDate unless wish to use default values\n",
    "    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n",
    "    all_master_lists[initial_search_term] = list(master_list)\n",
    "    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n",
    "    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n",
    "    lst_initial_queries = initial_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 Acquire initial RSV/RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Queries</th>\n",
       "      <th>Relative Search Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeast infection</td>\n",
       "      <td>0.679489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pill identifier</td>\n",
       "      <td>0.219542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plan b pill</td>\n",
       "      <td>0.062390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viagra pill</td>\n",
       "      <td>0.019676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast infection pill</td>\n",
       "      <td>0.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over the counter yeast infection pill</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleeping pill over the counter</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>over the counter water pill</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best over the counter diet pill</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best over the counter weight loss pill</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abortion pill over the counter cvs</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Queries  Relative Search Volume\n",
       "3                          yeast infection                0.679489\n",
       "9                          pill identifier                0.219542\n",
       "8                              plan b pill                0.062390\n",
       "7                              viagra pill                0.019676\n",
       "0                     yeast infection pill                0.014350\n",
       "1    over the counter yeast infection pill                0.001388\n",
       "2           sleeping pill over the counter                0.000871\n",
       "4              over the counter water pill                0.000749\n",
       "5          best over the counter diet pill                0.000696\n",
       "6   best over the counter weight loss pill                0.000609\n",
       "10      abortion pill over the counter cvs                0.000240"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ashley Kong January 27, 2021\n",
    "# ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n",
    "# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n",
    "\n",
    "#*** 30 iteration run for rsv and rsi start\n",
    "rsv = all_relative_search_volumes[initial_search_terms[0]]['US']\n",
    "\n",
    "queries = [list(d.keys())[0] for d in rsv]\n",
    "rsvs = [list(d.values())[0] for d in rsv]\n",
    "rsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n",
    "               columns =['Queries', 'Relative Search Volume'])\n",
    "rsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\n",
    "rsv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yeast infection pill': 100,\n",
       " 'over the counter yeast infection pill': 95,\n",
       " 'sleeping pill over the counter': 95,\n",
       " 'yeast infection': 90,\n",
       " 'over the counter water pill': 71,\n",
       " 'best over the counter diet pill': 52,\n",
       " 'best over the counter weight loss pill': 52,\n",
       " 'viagra pill': 52,\n",
       " 'plan b pill': 47,\n",
       " 'pill identifier': 9,\n",
       " 'abortion pill over the counter cvs': 9}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\n",
    "rsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 Conduct 30 iterations for initial term search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Queries</th>\n",
       "      <th>Relative Search Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast infection</td>\n",
       "      <td>0.679489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pill identifier</td>\n",
       "      <td>0.219542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plan b pill</td>\n",
       "      <td>0.062390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>viagra pill</td>\n",
       "      <td>0.019676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeast infection pill</td>\n",
       "      <td>0.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over the counter yeast infection pill</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sleeping pill over the counter</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>over the counter water pill</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>best over the counter diet pill</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best over the counter weight loss pill</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abortion pill over the counter cvs</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Queries  Relative Search Volume\n",
       "0                          yeast infection                0.679489\n",
       "1                          pill identifier                0.219542\n",
       "2                              plan b pill                0.062390\n",
       "3                              viagra pill                0.019676\n",
       "4                     yeast infection pill                0.014350\n",
       "5    over the counter yeast infection pill                0.001388\n",
       "6           sleeping pill over the counter                0.000871\n",
       "7              over the counter water pill                0.000749\n",
       "8          best over the counter diet pill                0.000696\n",
       "9   best over the counter weight loss pill                0.000609\n",
       "10      abortion pill over the counter cvs                0.000240"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ashley Kong January 27, 2021\n",
    "# Calculate the average relative search volume for 30 iterations\n",
    "# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n",
    "#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n",
    "\n",
    "# The process to get 30 iterations for the 'over the counter pill' search took: 3min. 2sec. 95 ms.\n",
    "# The process to get 1 iteration for the 'over the counter pill' search took: 3min. 27sec. 34ms.\n",
    "# If we were to have done 30 iterations using the old method it would have taken: 1.725 hours.\n",
    "# With this procedure we have improved our search algorithm, it now takes 2.93% of the original time\n",
    "# it would have to conduct a 30 iteration sample of a search for a given query.\n",
    "\n",
    "#### CODE FOR REPO\n",
    "for i in range(29):\n",
    "    for initial_search_term in initial_search_terms: \n",
    "        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n",
    "        all_master_lists[initial_search_term] = list(master_list)\n",
    "        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n",
    "        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n",
    "        lst_initial_queries = initial_queries\n",
    "\n",
    "        # Info for this iteration\n",
    "        rsv = all_relative_search_volumes[initial_search_terms[0]]['US']\n",
    "        \n",
    "        # Query and RSV for this iteration\n",
    "        queries = [list(d.keys())[0] for d in rsv]\n",
    "        rsvs = [list(d.values())[0] for d in rsv]\n",
    "        \n",
    "        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n",
    "\n",
    "        old_queries = rsv_df['Queries'].tolist()\n",
    "        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n",
    "        \n",
    "        query_list = rsv_df['Queries'].tolist()\n",
    "                \n",
    "        for new_query in new_data.keys():\n",
    "            if new_query in query_list:\n",
    "                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n",
    "            else:\n",
    "                old_queries.append(new_query)\n",
    "                old_rsvs.append(new_data[new_query])\n",
    "                query_list.append(new_query)\n",
    "        \n",
    "        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n",
    "                             \"Relative Search Volume\": old_rsvs})\n",
    "        \n",
    "        # Iteration for calculating relative search indexes for initial search term\n",
    "        \n",
    "        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\n",
    "        old_rsi_query = rsi.keys()\n",
    "        old_rsis = rsi.values()\n",
    "        new_rsi_query = new_rsi.keys()\n",
    "        new_rsis = new_rsi.values()\n",
    "        \n",
    "        q_list = list(rsi.keys())\n",
    "        \n",
    "        for new_query in new_rsi.keys():\n",
    "            if new_query in q_list:\n",
    "                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n",
    "            else: \n",
    "                rsi[new_query] = new_rsi[new_query]\n",
    "                q_list.append(new_query)\n",
    "                \n",
    "rsi= {q: rsi[q]/30 for q in rsi.keys()}\n",
    "rsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \n",
    "rsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\n",
    "rsv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Relative Search Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast infection pill</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over the counter yeast infection pill</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleeping pill over the counter</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeast infection</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>over the counter water pill</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best over the counter diet pill</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best over the counter weight loss pill</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>viagra pill</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plan b pill</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pill identifier</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abortion pill over the counter cvs</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Query  Relative Search Volume\n",
       "0                     yeast infection pill                     100\n",
       "1    over the counter yeast infection pill                      95\n",
       "2           sleeping pill over the counter                      95\n",
       "3                          yeast infection                      90\n",
       "4              over the counter water pill                      71\n",
       "5          best over the counter diet pill                      52\n",
       "6   best over the counter weight loss pill                      52\n",
       "7                              viagra pill                      52\n",
       "8                              plan b pill                      47\n",
       "9                          pill identifier                       9\n",
       "10      abortion pill over the counter cvs                       9"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\n",
    "rsi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 Save 30 Iteration RSV/RSI as .csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the relative search volume dataframe and relative search index dataframe into .csv files\n",
    "rsv_df.to_csv ('overthecounterpill_rsv.csv', header=True)\n",
    "rsv_df.to_csv ('ocp_abortionpill_abortionpillonline_rsi.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'over the counter pill': {'US': [{'query': 'yeast infection pill',\n",
       "    'value': 100},\n",
       "   {'query': 'over the counter yeast infection pill', 'value': 95},\n",
       "   {'query': 'sleeping pill over the counter', 'value': 95},\n",
       "   {'query': 'yeast infection', 'value': 90},\n",
       "   {'query': 'over the counter water pill', 'value': 71},\n",
       "   {'query': 'best over the counter diet pill', 'value': 52},\n",
       "   {'query': 'best over the counter weight loss pill', 'value': 52},\n",
       "   {'query': 'viagra pill', 'value': 52},\n",
       "   {'query': 'plan b pill', 'value': 47},\n",
       "   {'query': 'pill identifier', 'value': 9},\n",
       "   {'query': 'abortion pill over the counter cvs', 'value': 9}]}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_top_queries_rsi"
   ]
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt",
    "id": "c9dfdc69c74b436a9bf73ffe17aa215d",
    "idx": 1,
    "time": "2021-01-27T12:07:22.358Z",
    "type": "execution"
   },
   {
    "code": "# Import needed packages\nimport csv\nimport search\nimport simulate_keywords\nfrom google_client import GoogleClient",
    "id": "312de5ab0a9a40d09789fdaeff1e82a1",
    "idx": 2,
    "time": "2021-01-27T12:07:22.663Z",
    "type": "execution"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=\"AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI\"",
    "id": "d92bd106d2624273af6697e9da5af114",
    "idx": 3,
    "time": "2021-01-27T12:07:22.926Z",
    "type": "execution"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "idx": 4,
    "time": "2021-01-27T12:07:23.624Z",
    "type": "execution"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "idx": 5,
    "time": "2021-01-27T12:07:24.368Z",
    "type": "execution"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        print(simulation.initial_queries)       \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:07:25.310Z",
    "type": "execution"
   },
   {
    "id": "c9dfdc69c74b436a9bf73ffe17aa215d",
    "time": "2021-01-27T12:07:25.812Z",
    "type": "completion"
   },
   {
    "id": "312de5ab0a9a40d09789fdaeff1e82a1",
    "time": "2021-01-27T12:07:26.274Z",
    "type": "completion"
   },
   {
    "id": "d92bd106d2624273af6697e9da5af114",
    "time": "2021-01-27T12:07:26.280Z",
    "type": "completion"
   },
   {
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "time": "2021-01-27T12:07:26.318Z",
    "type": "completion"
   },
   {
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "time": "2021-01-27T12:07:26.322Z",
    "type": "completion"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:07:26.323Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "1f3038dde7084a358012d3987fd25752",
    "idx": 9,
    "time": "2021-01-27T12:07:36.755Z",
    "type": "execution"
   },
   {
    "id": "1f3038dde7084a358012d3987fd25752",
    "time": "2021-01-27T12:07:37.340Z",
    "type": "completion"
   },
   {
    "code": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt",
    "id": "c9dfdc69c74b436a9bf73ffe17aa215d",
    "idx": 1,
    "time": "2021-01-27T12:07:52.578Z",
    "type": "execution"
   },
   {
    "id": "c9dfdc69c74b436a9bf73ffe17aa215d",
    "time": "2021-01-27T12:07:52.666Z",
    "type": "completion"
   },
   {
    "code": "# Import needed packages\nimport csv\nimport search\nimport simulate_keywords\nfrom google_client import GoogleClient",
    "id": "312de5ab0a9a40d09789fdaeff1e82a1",
    "idx": 2,
    "time": "2021-01-27T12:07:52.857Z",
    "type": "execution"
   },
   {
    "id": "312de5ab0a9a40d09789fdaeff1e82a1",
    "time": "2021-01-27T12:07:52.924Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=\"AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI\"",
    "id": "d92bd106d2624273af6697e9da5af114",
    "idx": 3,
    "time": "2021-01-27T12:07:53.058Z",
    "type": "execution"
   },
   {
    "id": "d92bd106d2624273af6697e9da5af114",
    "time": "2021-01-27T12:07:53.123Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "idx": 4,
    "time": "2021-01-27T12:07:53.259Z",
    "type": "execution"
   },
   {
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "time": "2021-01-27T12:07:53.327Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "idx": 5,
    "time": "2021-01-27T12:07:53.714Z",
    "type": "execution"
   },
   {
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "time": "2021-01-27T12:07:53.777Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        print(simulation.initial_queries)       \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:07:54.121Z",
    "type": "execution"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:07:54.189Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5b2bf5fb263b4cf29ec2881327c4dbbc",
    "idx": 8,
    "time": "2021-01-27T12:07:56.093Z",
    "type": "execution"
   },
   {
    "id": "5b2bf5fb263b4cf29ec2881327c4dbbc",
    "time": "2021-01-27T12:07:56.169Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "1f3038dde7084a358012d3987fd25752",
    "idx": 9,
    "time": "2021-01-27T12:07:56.968Z",
    "type": "execution"
   },
   {
    "id": "1f3038dde7084a358012d3987fd25752",
    "time": "2021-01-27T12:07:57.413Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI",
    "id": "d92bd106d2624273af6697e9da5af114",
    "idx": 3,
    "time": "2021-01-27T12:12:19.693Z",
    "type": "execution"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "idx": 4,
    "time": "2021-01-27T12:12:20.422Z",
    "type": "execution"
   },
   {
    "id": "d92bd106d2624273af6697e9da5af114",
    "time": "2021-01-27T12:12:20.466Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "idx": 5,
    "time": "2021-01-27T12:12:21.422Z",
    "type": "execution"
   },
   {
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "time": "2021-01-27T12:12:21.852Z",
    "type": "completion"
   },
   {
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "time": "2021-01-27T12:12:21.854Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        print(simulation.initial_queries)       \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:12:22.339Z",
    "type": "execution"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:12:22.505Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5b2bf5fb263b4cf29ec2881327c4dbbc",
    "idx": 8,
    "time": "2021-01-27T12:12:24.352Z",
    "type": "execution"
   },
   {
    "id": "5b2bf5fb263b4cf29ec2881327c4dbbc",
    "time": "2021-01-27T12:12:24.444Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "1f3038dde7084a358012d3987fd25752",
    "idx": 9,
    "time": "2021-01-27T12:12:25.163Z",
    "type": "execution"
   },
   {
    "id": "1f3038dde7084a358012d3987fd25752",
    "time": "2021-01-27T12:12:27.252Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "idx": 10,
    "time": "2021-01-27T12:12:47.458Z",
    "type": "execution"
   },
   {
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "time": "2021-01-27T12:12:47.585Z",
    "type": "completion"
   },
   {
    "code": "lst = [1,2]\nnp.mean(lst)",
    "id": "df77f7cf002e41e088da6ada849e06a3",
    "idx": 11,
    "time": "2021-01-27T12:15:47.963Z",
    "type": "execution"
   },
   {
    "id": "df77f7cf002e41e088da6ada849e06a3",
    "time": "2021-01-27T12:15:48.078Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries\n    \n    rsv = all_relative_search_volumes['home abortion']['US']\n    rsvs = [list(d.values())[0] for d in rsv]\n    \n    new_rsv = [vol[i] + rsvs[i] for vol in rsv_df['Relative Search Volume']]\nrsv_df['Relative Search Volume']  =   np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:17:40.810Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:17:40.961Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries\n    \n    rsv = all_relative_search_volumes['home abortion']['US']\n    rsvs = [list(d.values())[0] for d in rsv]\n    \n    new_rsv = [vol[i] + rsvs[i] for vol in rsv_df['Relative Search Volume']]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:17:46.156Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:17:46.271Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n\n        new_rsv = [vol[i] + rsvs[i] for vol in rsv_df['Relative Search Volume']]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:18:04.438Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:18:06.069Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n\n        print(rsvs[0])\n        print(rsv_df['Relative Search Volume'][0])\n        \n        new_rsv = [vol[i] + rsvs[i] for vol in rsv_df['Relative Search Volume']]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:18:52.829Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:18:54.132Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n\n        print(rsvs[0])\n        print(rsv_df['Relative Search Volume'][0])\n        \n        new_rsv = [(vol[i] + rsvs[i]) for vol in rsv_df['Relative Search Volume']]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:20:00.744Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:20:01.974Z",
    "type": "completion"
   },
   {
    "code": "for i in range(29):\n    for initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n\n        print(rsvs[0])\n        print(rsv_df['Relative Search Volume'][0])\n        \n        new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:20:39.160Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:21:10.518Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:21:22.735Z",
    "type": "execution"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:21:22.805Z",
    "type": "completion"
   },
   {
    "code": "rsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df.to_csv ('homeabortion_rsv.csv', header=True)",
    "id": "f30c0f809048424788682ccbe04b60f1",
    "idx": 12,
    "time": "2021-01-27T12:21:44.158Z",
    "type": "execution"
   },
   {
    "id": "f30c0f809048424788682ccbe04b60f1",
    "time": "2021-01-27T12:21:44.236Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['over the counter pill']",
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "idx": 4,
    "time": "2021-01-27T12:25:44.465Z",
    "type": "execution"
   },
   {
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "time": "2021-01-27T12:25:44.538Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "idx": 5,
    "time": "2021-01-27T12:25:45.035Z",
    "type": "execution"
   },
   {
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "time": "2021-01-27T12:25:45.140Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:25:45.692Z",
    "type": "execution"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:25:45.763Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "1f3038dde7084a358012d3987fd25752",
    "idx": 9,
    "time": "2021-01-27T12:25:54.668Z",
    "type": "execution"
   },
   {
    "id": "1f3038dde7084a358012d3987fd25752",
    "time": "2021-01-27T12:25:57.294Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['over the counter pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "idx": 10,
    "time": "2021-01-27T12:26:03.467Z",
    "type": "execution"
   },
   {
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "time": "2021-01-27T12:26:03.556Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['over the counter pill']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:26:11.144Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:26:55.905Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "idx": 4,
    "time": "2021-01-27T12:28:22.070Z",
    "type": "execution"
   },
   {
    "id": "706fa24ef2a64a69b7ea12f115781a69",
    "time": "2021-01-27T12:28:22.144Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "idx": 5,
    "time": "2021-01-27T12:28:22.327Z",
    "type": "execution"
   },
   {
    "id": "3815072376d54c2f8e87d7844fb1b220",
    "time": "2021-01-27T12:28:22.389Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "idx": 6,
    "time": "2021-01-27T12:28:22.526Z",
    "type": "execution"
   },
   {
    "id": "d2e05780b4e740d2849fbbc17996e823",
    "time": "2021-01-27T12:28:22.636Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "1f3038dde7084a358012d3987fd25752",
    "idx": 9,
    "time": "2021-01-27T12:28:26.174Z",
    "type": "execution"
   },
   {
    "id": "1f3038dde7084a358012d3987fd25752",
    "time": "2021-01-27T12:28:28.041Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "idx": 10,
    "time": "2021-01-27T12:28:31.800Z",
    "type": "execution"
   },
   {
    "id": "decf4bc380f94c95bd968d71f9ad3535",
    "time": "2021-01-27T12:28:31.913Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Relative Search Volume'] = new_rsv\nrsv_df['Relative Search Volume']  =  np.mean(rsv_df['Relative Search Volume'])\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:29:13.476Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:29:41.093Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Relative Search Volume'] = new_rsv\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:30:15.918Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:30:42.636Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        rsv = all_relative_search_volumes['home abortion']['US']\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Relative Search Volume'] = new_rsv\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "idx": 11,
    "time": "2021-01-27T12:31:32.481Z",
    "type": "execution"
   },
   {
    "id": "ace5a8f05c5e4200bff085a08143b5d1",
    "time": "2021-01-27T12:31:59.639Z",
    "type": "completion"
   },
   {
    "code": "{\"a\":1 for i in range(2)}",
    "id": "125d90f9ac78461da5436407540dd4ac",
    "idx": 10,
    "time": "2021-01-28T04:29:15.715Z",
    "type": "execution"
   },
   {
    "id": "125d90f9ac78461da5436407540dd4ac",
    "time": "2021-01-28T04:29:15.796Z",
    "type": "completion"
   },
   {
    "code": "{\"a\":1 for i in range(3)}",
    "id": "125d90f9ac78461da5436407540dd4ac",
    "idx": 10,
    "time": "2021-01-28T04:29:18.647Z",
    "type": "execution"
   },
   {
    "id": "125d90f9ac78461da5436407540dd4ac",
    "time": "2021-01-28T04:29:18.718Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\ncounts = {query: 1 for query in queriees}\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "360ef415b7b74344844f99fbca2eba35",
    "idx": 10,
    "time": "2021-01-28T04:29:41.455Z",
    "type": "execution"
   },
   {
    "id": "360ef415b7b74344844f99fbca2eba35",
    "time": "2021-01-28T04:29:41.583Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "989bdef66d8e40658ca4dee150447019",
    "idx": 9,
    "time": "2021-01-28T04:29:44.604Z",
    "type": "execution"
   },
   {
    "id": "989bdef66d8e40658ca4dee150447019",
    "time": "2021-01-28T04:29:44.683Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "d29b5d7e2b2d431f8b49c3378470ff06",
    "idx": 6,
    "time": "2021-01-28T04:29:49.320Z",
    "type": "execution"
   },
   {
    "id": "d29b5d7e2b2d431f8b49c3378470ff06",
    "time": "2021-01-28T04:29:49.408Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "989bdef66d8e40658ca4dee150447019",
    "idx": 9,
    "time": "2021-01-28T04:29:51.797Z",
    "type": "execution"
   },
   {
    "id": "989bdef66d8e40658ca4dee150447019",
    "time": "2021-01-28T04:29:51.882Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "c664fc54e79c49758da405eed3f440e1",
    "idx": 4,
    "time": "2021-01-28T04:30:00.429Z",
    "type": "execution"
   },
   {
    "id": "c664fc54e79c49758da405eed3f440e1",
    "time": "2021-01-28T04:30:00.502Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "989bdef66d8e40658ca4dee150447019",
    "idx": 9,
    "time": "2021-01-28T04:30:03.480Z",
    "type": "execution"
   },
   {
    "id": "989bdef66d8e40658ca4dee150447019",
    "time": "2021-01-28T04:30:03.905Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\ncounts = {query: 1 for query in queriees}\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "360ef415b7b74344844f99fbca2eba35",
    "idx": 10,
    "time": "2021-01-28T04:30:04.033Z",
    "type": "execution"
   },
   {
    "id": "360ef415b7b74344844f99fbca2eba35",
    "time": "2021-01-28T04:30:04.121Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\ncounts = {query: 1 for query in queriees}\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "360ef415b7b74344844f99fbca2eba35",
    "idx": 10,
    "time": "2021-01-28T04:30:30.926Z",
    "type": "execution"
   },
   {
    "id": "360ef415b7b74344844f99fbca2eba35",
    "time": "2021-01-28T04:30:31.036Z",
    "type": "completion"
   },
   {
    "code": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt",
    "id": "d895f9e028b44a40987f026debcddbb9",
    "idx": 1,
    "time": "2021-01-28T04:50:30.524Z",
    "type": "execution"
   },
   {
    "id": "d895f9e028b44a40987f026debcddbb9",
    "time": "2021-01-28T04:50:31.246Z",
    "type": "completion"
   },
   {
    "code": "# Import needed packages\nimport csv\nimport search\nimport simulate_keywords\nfrom google_client import GoogleClient",
    "id": "327c627a658b4f24af08fa4e45a1a30c",
    "idx": 2,
    "time": "2021-01-28T04:50:31.549Z",
    "type": "execution"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI",
    "id": "206957e6eeb74d4abed624b34a115d4c",
    "idx": 3,
    "time": "2021-01-28T04:50:31.912Z",
    "type": "execution"
   },
   {
    "id": "327c627a658b4f24af08fa4e45a1a30c",
    "time": "2021-01-28T04:50:32.030Z",
    "type": "completion"
   },
   {
    "id": "206957e6eeb74d4abed624b34a115d4c",
    "time": "2021-01-28T04:50:32.033Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T04:50:32.254Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T04:50:32.323Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T04:50:32.646Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T04:50:32.713Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T04:50:33.032Z",
    "type": "execution"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T04:50:33.102Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T04:50:34.222Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T04:50:34.300Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T04:50:34.895Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T04:50:37.326Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T04:50:41.249Z",
    "type": "execution"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T04:50:41.369Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries']\n        old_rsvs = rsv_df['Relative Search Volume']\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:50:52.801Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:50:54.414Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries']\n        old_rsvs = rsv_df['Relative Search Volume']\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(old_queries[old_queries.index(query)])\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:51:17.000Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:51:18.614Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries']\n        old_rsvs = rsv_df['Relative Search Volume']\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:52:58.196Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:53:00.287Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries']\n        old_rsvs = rsv_df['Relative Search Volume']\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:53:16.179Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:53:17.903Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries']\n        old_rsvs = rsv_df['Relative Search Volume']\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(type(query))\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:53:30.669Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:53:34.941Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(type(query))\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:54:20.396Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:54:21.833Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n       \"\"\"\" for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(type(query))\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\"\"\"\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:57:37.001Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:57:37.174Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n    \"\"\"\" for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(type(query))\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\"\"\"\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:57:45.833Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:57:45.914Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n    \"\"\"\" for query in rsv_df['Queries']:\n            if query in new_data.keys():\n                print(query)\n                print(type(query))\n                print(old_queries.index(query))\n                old_queries[old_queries.index(query)] = old_rsvs[old_queries.index(query)] + new_data[query]\n            else:\n                old_queries.append(query)\n                old_rsvs.append(new_data[query])\"\"\"\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:58:13.277Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:58:13.530Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        rsv_df['Queries'] = old_queries\n        rsv_df['Relative Search Volume'] = old_rsvs\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:58:25.671Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:58:27.481Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame(\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queres)\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:59:26.849Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:59:27.343Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame(\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queries)\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:59:35.514Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T04:59:35.676Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queries})\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'] / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T04:59:57.603Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:00:32.966Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queries})\nrsv_df['Relative Search Volume']  =  rsv_df['Relative Search Volume'].tolist() / 30\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:01:19.991Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:01:52.144Z",
    "type": "completion"
   },
   {
    "code": "[1,2] / 3",
    "id": "29bc7fa5cba34117a64ba58df4ba27f6",
    "idx": 11,
    "time": "2021-01-28T05:02:08.370Z",
    "type": "execution"
   },
   {
    "id": "29bc7fa5cba34117a64ba58df4ba27f6",
    "time": "2021-01-28T05:02:08.493Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queries})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:03:05.732Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:03:37.707Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_queries})\nprint(type(rsv_df['Relative Search Volume'][0]))\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:05:01.298Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:05:30.036Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:05:48.663Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:05:50.013Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(old_queries)\n        print(len(old_rsvs))\n        print(old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:07:11.379Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:07:13.493Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        #print(old_queries)\n        print(len(old_rsvs))\n        #print(old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:08:38.157Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:08:39.539Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:08:54.737Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:08:54.805Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:08:54.982Z",
    "type": "execution"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T05:08:55.225Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:08:55.263Z",
    "type": "completion"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T05:08:55.357Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T05:08:57.172Z",
    "type": "execution"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:08:57.914Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T05:08:59.034Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:08:59.106Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:08:59.292Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:08:59.336Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        #print(old_queries)\n        print(len(old_rsvs))\n        #print(old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:09:01.543Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:09:05.912Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:09:18.722Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:09:18.808Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:09:19.028Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:09:19.125Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T05:09:19.246Z",
    "type": "execution"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T05:09:19.322Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T05:09:20.493Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T05:09:20.578Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:09:21.371Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:09:22.886Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:09:23.569Z",
    "type": "execution"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:09:23.663Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:09:38.354Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:09:39.846Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for i in range(len(new_data.keys())):\n            new_query = new_data.keys(i)\n            new_rsv = new_data.values(i)\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:16:35.222Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:16:36.912Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for i in range(len(new_data.keys())):\n            new_query = new_data.keys()[i]\n            new_rsv = new_data.values()[i]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:16:48.447Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:16:49.545Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for i in range(len(list(new_data.keys()))):\n            new_query = list(new_data.keys())[i]\n            new_rsv = list(new_data.values())[i]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:17:24.075Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:17:26.196Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for j in range(len(list(new_data.keys()))):\n            new_query = list(new_data.keys())[j]\n            new_rsv = list(new_data.values())[j]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_queries.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:17:54.092Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:17:55.404Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for j in range(len(list(new_data.keys()))):\n            new_query = list(new_data.keys())[j]\n            new_rsv = list(new_data.values())[j]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:18:30.217Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:19:02.374Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:19:57.397Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:19:57.473Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:19:57.656Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:19:57.719Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T05:19:57.876Z",
    "type": "execution"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T05:19:57.973Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T05:19:58.601Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T05:19:58.675Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:19:59.369Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:20:00.579Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:20:00.655Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:20:00.701Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for j in range(len(list(new_data.keys()))):\n            new_query = list(new_data.keys())[j]\n            new_rsv = list(new_data.values())[j]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:20:01.291Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:20:33.163Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        for j in range(len(list(new_data.keys()))):\n            new_query = list(new_data.keys())[j]\n            new_rsv = list(new_data.values())[j]\n            existing = False\n            for og_query in rsv_df[\"Queries\"].tolist():\n                if og_query == new_query:\n                    old_queries[old_queries.index(og_query)] = old_rsvs[old_queries.index(og_query)] + new_data[new_query]\n                    existing = True\n                    break\n            if existing == False:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                \n       # for new_query in new_data.keys():\n            #if new_query in rsv_df['Queries']:\n               # old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n           # else:\n              #  old_queries.append(new_query)\n              #  old_queries.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 11,
    "time": "2021-01-28T05:21:18.074Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:21:20.543Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']?",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:22:07.581Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:22:07.654Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:22:07.969Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:22:08.054Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:22:14.647Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:22:14.722Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:22:15.067Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:22:15.134Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T05:22:15.559Z",
    "type": "execution"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T05:22:15.640Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T05:22:16.738Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T05:22:16.813Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:22:18.310Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:22:19.301Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:22:19.545Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:22:19.599Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n                \n        for new_query in new_data.keys():\n            if new_query in rsv_df['Queries']:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:22:22.617Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:22:24.832Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(len(old_queries))\n        print(\"queries\", old_queries)\n        print(len(old_rsvs))\n        print(\"rsvs\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:24:48.381Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:24:50.698Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(\"LENGTH OF OLD QUERIES\" len(old_queries))\n        print(\"QUERIES\", old_queries)\n        print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:25:43.794Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:25:43.911Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_queries[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        print(\"QUERIES\", old_queries)\n        print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:25:57.149Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:25:59.519Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:26:48.547Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:26:49.195Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:26:50.043Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:26:50.049Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n\nfor i in range(2):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n        print(new_data)\n        \n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        print(\"QUERIES\", old_queries)\n        print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:26:52.615Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:26:54.979Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:28:16.941Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:28:17.611Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:28:17.947Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:28:17.966Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:30:24.061Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:30:54.815Z",
    "type": "completion"
   },
   {
    "code": "all_top_queries_rsi",
    "id": "f5b9ef874b5f4989b93b799453f193e1",
    "idx": 13,
    "time": "2021-01-28T05:31:26.557Z",
    "type": "execution"
   },
   {
    "id": "f5b9ef874b5f4989b93b799453f193e1",
    "time": "2021-01-28T05:31:26.639Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe into .csv file\nrsv_df.to_csv ('homeabortion_rsv.csv', header=True)",
    "id": "282e0764ed464fbc8615db55ae5c7457",
    "idx": 12,
    "time": "2021-01-28T05:32:12.618Z",
    "type": "execution"
   },
   {
    "id": "282e0764ed464fbc8615db55ae5c7457",
    "time": "2021-01-28T05:32:12.707Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:32:15.810Z",
    "type": "execution"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:32:15.911Z",
    "type": "completion"
   },
   {
    "code": "all_top_queries_rsi",
    "id": "f5b9ef874b5f4989b93b799453f193e1",
    "idx": 13,
    "time": "2021-01-28T05:32:19.415Z",
    "type": "execution"
   },
   {
    "id": "f5b9ef874b5f4989b93b799453f193e1",
    "time": "2021-01-28T05:32:19.491Z",
    "type": "completion"
   },
   {
    "code": "all_top_queries_rsi['home abortion'][\"US\"]",
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "idx": 11,
    "time": "2021-01-28T05:38:19.453Z",
    "type": "execution"
   },
   {
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "time": "2021-01-28T05:38:19.539Z",
    "type": "completion"
   },
   {
    "code": "{d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}",
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "idx": 11,
    "time": "2021-01-28T05:39:16.093Z",
    "type": "execution"
   },
   {
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "time": "2021-01-28T05:39:16.181Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\nrsi",
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "idx": 11,
    "time": "2021-01-28T05:39:34.972Z",
    "type": "execution"
   },
   {
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "time": "2021-01-28T05:39:35.065Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n    \nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:49:27.349Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:49:42.821Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n \nrsi = {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:50:58.680Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:51:34.477Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "2f3deb54995749188768bf3ef3507774",
    "idx": 13,
    "time": "2021-01-28T05:51:37.608Z",
    "type": "execution"
   },
   {
    "id": "2f3deb54995749188768bf3ef3507774",
    "time": "2021-01-28T05:51:38.009Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n \n#\nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:52:39.498Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:53:11.217Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "2f3deb54995749188768bf3ef3507774",
    "idx": 13,
    "time": "2021-01-28T05:53:13.713Z",
    "type": "execution"
   },
   {
    "id": "2f3deb54995749188768bf3ef3507774",
    "time": "2021-01-28T05:53:13.784Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "idx": 4,
    "time": "2021-01-28T05:53:38.166Z",
    "type": "execution"
   },
   {
    "id": "26513184857a47a88d3ce1d27ea256ac",
    "time": "2021-01-28T05:53:38.270Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "aee9760ec5e7430595df867ba8f47251",
    "idx": 5,
    "time": "2021-01-28T05:53:38.349Z",
    "type": "execution"
   },
   {
    "id": "aee9760ec5e7430595df867ba8f47251",
    "time": "2021-01-28T05:53:38.435Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "idx": 6,
    "time": "2021-01-28T05:53:38.538Z",
    "type": "execution"
   },
   {
    "id": "4092b2cf0b2247cf886394f4451fc358",
    "time": "2021-01-28T05:53:38.610Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "idx": 8,
    "time": "2021-01-28T05:53:39.303Z",
    "type": "execution"
   },
   {
    "id": "a4cd2920cefd4991bef3afdb534792c9",
    "time": "2021-01-28T05:53:39.391Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "900060af351946db8f8d8a5695ec8172",
    "idx": 9,
    "time": "2021-01-28T05:53:40.418Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "idx": 10,
    "time": "2021-01-28T05:53:41.338Z",
    "type": "execution"
   },
   {
    "id": "900060af351946db8f8d8a5695ec8172",
    "time": "2021-01-28T05:53:41.993Z",
    "type": "completion"
   },
   {
    "id": "4017cfab2dac44cd8cb6cab4b4ccbaff",
    "time": "2021-01-28T05:53:41.998Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\nrsi",
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "idx": 11,
    "time": "2021-01-28T05:53:43.722Z",
    "type": "execution"
   },
   {
    "id": "4d016a480b9a431fbd5f3bcb0b8c17ea",
    "time": "2021-01-28T05:53:43.811Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "45521450c3af425f872aec02f40248f5",
    "idx": 12,
    "time": "2021-01-28T05:53:45.979Z",
    "type": "execution"
   },
   {
    "id": "45521450c3af425f872aec02f40248f5",
    "time": "2021-01-28T05:54:16.200Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "2f3deb54995749188768bf3ef3507774",
    "idx": 13,
    "time": "2021-01-28T05:54:35.907Z",
    "type": "execution"
   },
   {
    "id": "2f3deb54995749188768bf3ef3507774",
    "time": "2021-01-28T05:54:35.985Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe into .csv file\nrsv_df.to_csv ('homeabortion_rsv.csv', header=True)",
    "id": "282e0764ed464fbc8615db55ae5c7457",
    "idx": 14,
    "time": "2021-01-28T05:55:00.568Z",
    "type": "execution"
   },
   {
    "code": "###### IMPORTANT NOTEBOOK FOR REPO X2",
    "id": "fc7e3b649169422a86247fdee7f29e70",
    "idx": 0,
    "time": "2021-01-28T05:57:44.803Z",
    "type": "execution"
   },
   {
    "id": "fc7e3b649169422a86247fdee7f29e70",
    "time": "2021-01-28T05:57:44.873Z",
    "type": "completion"
   },
   {
    "code": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt",
    "id": "fc4f124bdca149f1a62d2c1ee457a353",
    "idx": 1,
    "time": "2021-01-28T05:57:44.989Z",
    "type": "execution"
   },
   {
    "code": "# Import needed packages\nimport csv\nimport search\nimport simulate_keywords\nfrom google_client import GoogleClient",
    "id": "0712f6b9eefc43c59deab22f2c14d434",
    "idx": 2,
    "time": "2021-01-28T05:57:45.186Z",
    "type": "execution"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T05:57:45.355Z",
    "type": "execution"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['home abortion']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T05:57:45.514Z",
    "type": "execution"
   },
   {
    "id": "fc4f124bdca149f1a62d2c1ee457a353",
    "time": "2021-01-28T05:57:45.614Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T05:57:45.687Z",
    "type": "execution"
   },
   {
    "id": "0712f6b9eefc43c59deab22f2c14d434",
    "time": "2021-01-28T05:57:46.057Z",
    "type": "completion"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T05:57:46.060Z",
    "type": "completion"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T05:57:46.107Z",
    "type": "completion"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T05:57:46.112Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T05:57:46.262Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T05:57:46.329Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T05:57:47.159Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T05:57:47.239Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T05:57:47.952Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T05:57:49.307Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['home abortion']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T05:57:49.772Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T05:57:49.863Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T05:57:51.781Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T05:57:51.859Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['home abortion']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['home abortion'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T05:57:53.306Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T05:58:22.937Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T05:58:47.299Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T05:58:47.457Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe into .csv file\nrsv_df.to_csv ('homeabortion_rsv.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T05:58:48.880Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T05:58:48.962Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion at home']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:05:43.733Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:05:43.825Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:05:44.014Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:05:44.083Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:05:44.411Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:05:44.484Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:05:45.792Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:05:45.870Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:05:46.739Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:05:47.898Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['buy abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:11:26.056Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:11:26.134Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:11:26.579Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:11:26.652Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:11:37.774Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:11:37.865Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:11:43.775Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:11:45.397Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['buy abortion pill online']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:12:03.802Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:12:03.918Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:12:13.483Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:12:13.582Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['buy abortion pill online']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:12:32.375Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:12:48.911Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:12:57.456Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:12:57.531Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe into .csv file\nrsv_df.to_csv ('homeabortion_rsv.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T06:13:07.056Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T06:13:07.142Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe into .csv file\nrsv_df.to_csv ('buyabortionpillonline_rsv.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T06:13:57.060Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T06:13:57.139Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['buy abortion pill kit online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:14:21.305Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:14:21.378Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:14:21.681Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:14:21.763Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:14:22.181Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:14:22.258Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:14:23.267Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:14:23.362Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:14:24.016Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:14:24.889Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['over the counter pill']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:19:33.520Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:19:33.641Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:19:33.859Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:19:34.040Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:19:34.513Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:19:34.586Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:19:37.881Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:19:37.955Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:19:39.524Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:19:42.438Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['over the counter pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:19:46.819Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:19:46.899Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:19:50.338Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:19:50.431Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['over the counter pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:19:58.446Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:19:58.535Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['over the counter pill']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:20:06.423Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:20:08.622Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:20:21.635Z",
    "type": "execution"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\nrsv = all_relative_search_volumes['over the counter pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:20:21.930Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:20:23.439Z",
    "type": "completion"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:20:23.459Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['over the counter pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:20:24.227Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:20:24.399Z",
    "type": "completion"
   },
   {
    "code": "# Calculate the average relative search volume \n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['over the counter pill']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['over the counter pill'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:20:25.901Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:21:21.655Z",
    "type": "completion"
   },
   {
    "code": "rsi",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:21:33.477Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:21:33.556Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame(rsi)\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:22:06.847Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:22:07.011Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:22:46.025Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:22:46.127Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:22:54.321Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:22:54.391Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe and relative search index dataframe into .csv files\nrsv_df.to_csv ('overthecounterpill_rsv.csv', header=True)\nrsv_df.to_csv ('ocp_rsi.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T06:23:53.701Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T06:23:53.785Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:29:59.612Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:29:59.693Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:29:59.841Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:29:59.981Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:30:00.196Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:30:00.273Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:30:01.224Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:30:01.292Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:30:01.957Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:30:06.738Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['over the counter pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:30:06.781Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:30:06.878Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:30:13.549Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:30:13.682Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['over the counter pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:31:35.241Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:31:35.341Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:31:44.782Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:31:44.879Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['abortion pill']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:32:15.693Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:33:58.912Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:34:15.015Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:34:15.151Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe and relative search index dataframe into .csv files\n#rsv_df.to_csv ('overthecounterpill_rsv.csv', header=True)\nrsv_df.to_csv ('ocp_abortionpill_rsi.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T06:34:45.951Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T06:34:46.023Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:36:30.632Z",
    "type": "execution"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:36:30.863Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:36:31.080Z",
    "type": "completion"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:36:31.082Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:36:31.113Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:36:31.275Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:36:31.884Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:36:32.127Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:36:32.339Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:36:34.003Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill online ']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:36:38.199Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:36:38.326Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill online']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:36:41.876Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:36:41.995Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:36:47.301Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:36:48.700Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['abortion pill online']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill online'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:36:58.061Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:37:15.809Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:37:34.530Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:37:34.655Z",
    "type": "completion"
   },
   {
    "code": "# Convert the relative search volume dataframe and relative search index dataframe into .csv files\n#rsv_df.to_csv ('overthecounterpill_rsv.csv', header=True)\nrsv_df.to_csv ('ocp_abortionpill_abortionpillonline_rsi.csv', header=True)",
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "idx": 14,
    "time": "2021-01-28T06:37:52.770Z",
    "type": "execution"
   },
   {
    "id": "68b1641de67a44f0878dc5c611ea58a5",
    "time": "2021-01-28T06:37:52.852Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['order abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:38:14.486Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:38:14.553Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:38:14.745Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:38:14.824Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:38:15.085Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:38:15.153Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:38:18.820Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:38:19.756Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['order abortion pill online\t']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:38:36.223Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:38:36.299Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:38:37.070Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:38:37.135Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['order abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:38:40.281Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:38:40.345Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:38:40.523Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:38:40.605Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:38:40.845Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:38:40.913Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:38:41.781Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:38:41.850Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:38:42.566Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:38:43.105Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['over the counter pill']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:40:00.674Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:40:00.753Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:40:00.920Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:40:00.997Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:40:01.151Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:40:01.241Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:40:02.695Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:40:02.764Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:40:05.233Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:40:07.877Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['over the counter pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:40:13.434Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:40:13.527Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:40:14.587Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:40:14.673Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n\n# The process to find the data for 'over the counter pill' took: \n\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['over the counter pill']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['over the counter pill'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:40:30.313Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:41:16.525Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:41:19.734Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:41:19.828Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:41:30.398Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:41:30.479Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:41:30.820Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:41:30.891Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:41:31.437Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:41:31.533Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:41:34.489Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:41:34.793Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:41:36.367Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:41:40.047Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:41:41.272Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:41:41.356Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:41:45.230Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:41:45.321Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:41:50.082Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:41:50.176Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n\n# The process to find the data for 'over the counter pill' took: \n\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['abortion pill']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['abortion pill'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:42:03.585Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:43:28.848Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:43:32.860Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:43:32.945Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:43:38.761Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:43:38.843Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:43:41.925Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:43:42.648Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill online']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:43:45.305Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:43:45.407Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:43:55.946Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:43:56.010Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:43:56.109Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:43:56.197Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:43:56.270Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:43:56.341Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:43:56.575Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:43:56.643Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:43:56.915Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:43:57.462Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:44:09.928Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:44:10.003Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:44:10.128Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:44:10.201Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:44:10.277Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:44:10.360Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:44:10.970Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:44:11.043Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:44:11.326Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:44:11.757Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:44:28.300Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:44:28.370Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:44:28.476Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:44:28.541Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:44:28.652Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:44:28.734Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:44:29.608Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:44:29.698Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:44:32.232Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:44:32.811Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['buy abortion pill online']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T06:44:42.069Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T06:44:42.177Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T06:44:42.265Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T06:44:42.329Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T06:44:42.609Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T06:44:42.690Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T06:44:43.443Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T06:44:43.511Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T06:44:44.070Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T06:44:44.991Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['abortion pill online']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:44:48.716Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:44:48.821Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes['buy abortion pill online']['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T06:44:54.041Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T06:44:54.170Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:44:57.422Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:44:57.519Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T06:45:01.919Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T06:45:02.018Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n\n# The process to find the data for 'over the counter pill' took: \n\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes['buy abortion pill online']['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi['buy abortion pill online'][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T06:45:15.536Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T06:45:30.221Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 13,
    "time": "2021-01-28T06:45:31.941Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T06:45:32.018Z",
    "type": "completion"
   },
   {
    "code": "# Control your initial search terms which you would like to run the simulation for here\ninitial_search_terms = ['over the counter pill']",
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "idx": 4,
    "time": "2021-01-28T07:03:57.284Z",
    "type": "execution"
   },
   {
    "id": "ca05d4506801473082d33eb4dd390f1c",
    "time": "2021-01-28T07:03:57.354Z",
    "type": "completion"
   },
   {
    "code": "def load_geolocations(): \n    locations = []\n    with open(simulate_keywords.Simulation.LOCATIONS_FILE, \"r\") as csvfile: \n        reader = csv.DictReader(csvfile)\n        for row in reader: \n            code = row[\"geo_code\"]\n            description = row[\"description\"]\n            locations.append({\"code\": code, \"description\": description})\n    return locations",
    "id": "41e37f2326b74367b906fb3490058acc",
    "idx": 5,
    "time": "2021-01-28T07:03:57.447Z",
    "type": "execution"
   },
   {
    "id": "41e37f2326b74367b906fb3490058acc",
    "time": "2021-01-28T07:03:57.512Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nGenerate master list of top queries for all geolocations during the specified time period\nGet relative search volume of top queries for initial search term\n\"\"\"\ndef run_simulation(initial_search_term, startDateTrends='2019-11', endDateTrends='2020-11', startDateTimelines='2019-11-01', endDateTimelines='2020-11-01'): \n    master_list = set()\n    relative_search_volumes = dict()\n    #This will contain a mapping of Location -> list of top queries and their associated relative search index\n    top_queries_relative_search_index = dict()\n    for loc in load_geolocations(): \n        \n        simulation = simulate_keywords.Simulation(initial_search_term, loc, startDateTrends, endDateTrends, startDateTimelines, endDateTimelines)\n        simulation.generate_keywords()\n        simulation.get_relative_search_volumes()\n        simulation.generate_simulation_csvs()\n        level_queries = {}\n        queryLevel = 1\n        \"\"\"//**for level in simulation.initial_queries['level']:\n            top_queries_in_level = [q['query'] for q in simulation.initial_queries if q['level'] == level]\n            top_queries[level] = top_queries_in_level\n            for query in top_queries_in_level:\n                master_list.add(query)\n                if (queryLevel not in level_queries.keys()):\n                    level_queries[queryLevel] = [query]\n                else:\n                    level_queries[queryLevel] = level_queries[queryLevel].append(query)\n            queryLevel +=1\n        while (run_simulation(initial_search_term, startDateTrends='2019-08', \n                              endDateTrends='2020-08', startDateTimelines='2019-08-01', \n                              endDateTimelines='2020-08-01'))*//\"\"\"\n        \n        #print(simulation.initial_queries)   \n        \n        #top_queries = [q['query'] for q in simulation.initial_queries if q['level'] == 1]\n        top_queries = [q['query'] for q in simulation.initial_queries]\n        query_rel_search_index = [{'query': q['query'], 'value': q['value']} for q in simulation.initial_queries]\n        # each q holds the properties of each relevant search query ie. the query, query level, etc.\n        for query in top_queries: \n             master_list.add(query)\n        relative_search_volumes[loc['code']] = simulation.relative_search_volumes\n        top_queries_relative_search_index[loc['code']] = query_rel_search_index\n    return master_list, relative_search_volumes, top_queries_relative_search_index, simulation.initial_queries",
    "id": "383770ba2a054bf393347fa10a6d3487",
    "idx": 6,
    "time": "2021-01-28T07:03:57.614Z",
    "type": "execution"
   },
   {
    "id": "383770ba2a054bf393347fa10a6d3487",
    "time": "2021-01-28T07:03:57.687Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong October 18, 2020\n# remove duplicate relevant search terms \n# and return list of dictionaries of \n# unique queries and their respective relevant serach indices\ndef remove_duplicates(running_log_of_relevant_terms_list, list_of_dictionaries) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_dictionaries:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    unique_queries = restandardize_rsi(unique_queries)\n    return unique_queries\n\n# Ashley Kong November 17, 2020\n# Restandardize the relative search index\n# after obtaining unique list of relevant search terms\n# for a given initial search term(can be a term from a specific level)\n\ndef restandardize_rsi(unique_queries_dict): \n                    # {abortion pill: ###, etc.}\n    total = sum([item for item in list(unique_queries_dict.values())])\n    for query in list(unique_queries_dict.keys()):\n        unique_queries_dict[query] = unique_queries_dict[query]/ total\n    return unique_queries_dict\n\n\n# Ashley Kong November 17, 2020\n# Running log of all levels and terms in a single iteration\ndef add_level_log(new_level, origin_initial_term, dictionary_rsi_terms):\n                # ex. 1, 'abortion pill', ('abortion': ###)\n                # origin_initial_term will give us the previous term\n                # that the new level relevant search terms are for\n    \n    level_dict = {}\n    #check if the level exists in level_log\n    if new_level in list(level_log.keys()):\n        level_dict = level_log[new_level] #ex. level_log[1] --> \n                                    #{'abortion' ie. prev level term:{this level term: ####, etc.}}   \n    level_dict[origin_initial_term] = dictionary_rsi_terms\n    level_log[new_level] = level_dict\n    return level_log\n    \n\n",
    "id": "5f533805de3b4269b2a27a87756558cf",
    "idx": 8,
    "time": "2021-01-28T07:03:58.759Z",
    "type": "execution"
   },
   {
    "id": "5f533805de3b4269b2a27a87756558cf",
    "time": "2021-01-28T07:03:58.852Z",
    "type": "completion"
   },
   {
    "code": "\"\"\"\nRun the simulation for all initial search terms \nGenerates a dictionary mapping initial_search_term to its master list for all locations\nGenerates a dictionary mapping initial_serach_term to its relative search volumes for all locations\n\"\"\"\nall_master_lists = dict()\nall_relative_search_volumes = dict()\nall_top_queries_rsi = dict()\nlst_initial_queries = []\nfor initial_search_term in initial_search_terms: \n    # Note: must specify explicit startDate & endDate unless wish to use default values\n    master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n    all_master_lists[initial_search_term] = list(master_list)\n    all_relative_search_volumes[initial_search_term] = relative_search_volumes\n    all_top_queries_rsi[initial_search_term] = top_queries_rsi\n    lst_initial_queries = initial_queries",
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "idx": 9,
    "time": "2021-01-28T07:04:00.268Z",
    "type": "execution"
   },
   {
    "id": "b27a53d800954b1a8c6108e475fe8344",
    "time": "2021-01-28T07:04:02.855Z",
    "type": "completion"
   },
   {
    "code": "#ONLY APPLIED TO THE LEVEL 1 TERMS AKA THE ORIGINAL INITIAL SEARCH TERM'S FOLLOW UP TERMS\n# RUN THIS ***ONLY ONCE*** FOR THE ORIGINAL INITIAL SEARCH TERM\n\n#*** 30 iteration run for rsv and rsi start\nrsv = all_relative_search_volumes[initial_search_terms[0]]['US']\n\nqueries = [list(d.keys())[0] for d in rsv]\nrsvs = [list(d.values())[0] for d in rsv]\nrsv_df = pd.DataFrame(list(zip(queries, rsvs)), \n               columns =['Queries', 'Relative Search Volume'])\nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df",
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "idx": 10,
    "time": "2021-01-28T07:04:22.734Z",
    "type": "execution"
   },
   {
    "id": "4bac2ea2f03545efa025a11d4a10ea2f",
    "time": "2021-01-28T07:04:22.862Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 11,
    "time": "2021-01-28T07:04:38.662Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T07:04:38.770Z",
    "type": "completion"
   },
   {
    "code": "# Ashley Kong 1/27/21\n# Calculate the average relative search volume for 30 iterations\n# NOTE: RSV's will be calculated for each 30 iteration run, but we only want \n#       the RSV's for the top queries. Do not use the RSV for level 2 terms and beyond.\n\n# The process to get 30 iterations for the 'over the counter pill' search took: 3min. 2sec. 95 ms.\n# The process to get 1 iteration for the 'over the counter pill' search took: 3min. 27sec. 34ms.\n# If we were to have done 30 iterations using the old method it would have taken: 1.725 hours.\n# With this procedure we have improved our search algorithm, it now takes 2.9% of the original time\n# it would have to conduct a 30 iteration sample of a search for a given query.\n\n#### CODE FOR REPO\nfor i in range(29):\n    for initial_search_term in initial_search_terms: \n        master_list, relative_search_volumes, top_queries_rsi, initial_queries = run_simulation(initial_search_term)\n        all_master_lists[initial_search_term] = list(master_list)\n        all_relative_search_volumes[initial_search_term] = relative_search_volumes\n        all_top_queries_rsi[initial_search_term] = top_queries_rsi\n        lst_initial_queries = initial_queries\n\n        #info for this iteration\n        rsv = all_relative_search_volumes[initial_search_terms[0]]['US']\n        \n        #query and rsv for this iteration\n        queries = [list(d.keys())[0] for d in rsv]\n        rsvs = [list(d.values())[0] for d in rsv]\n        \n        new_data = {queries[i]: rsvs[i] for i in range(len(queries))}\n\n        old_queries = rsv_df['Queries'].tolist()\n        old_rsvs = rsv_df['Relative Search Volume'].tolist()\n        \n        ####\n        \n        query_list = rsv_df['Queries'].tolist()\n                \n        for new_query in new_data.keys():\n            if new_query in query_list:\n                old_rsvs[old_queries.index(new_query)] = old_rsvs[old_queries.index(new_query)] + new_data[new_query]\n            else:\n                old_queries.append(new_query)\n                old_rsvs.append(new_data[new_query])\n                query_list.append(new_query)\n        \n        #new_queries = [val for val in queries if val not in rsv_df['Queries']]\n        #for q in new_queries:\n        #    old_queries.append(q)\n        #new_rsvs = []\n           \n        # new rsv's for df    \n        #new_rsv = [(rsv_df['Relative Search Volume'][i] + rsvs[i]) for i in range(len(rsv_df))]\n        #rsv_df['Queries'] = old_queries\n        #rsv_df['Relative Search Volume'] = old_rsvs\n        \n        #print(\"LENGTH OF OLD QUERIES\", len(old_queries))\n        #print(\"QUERIES\", old_queries)\n        #print(\"LENGTH OF OLD RSVS\", len(old_rsvs))\n        #print(\"RELATVIE SEARCH VOUME\", old_rsvs)\n        rsv_df = pd.DataFrame({\"Queries\": old_queries,\n                             \"Relative Search Volume\": old_rsvs})\n        \n        # Iteration for calculating relative search indexes for initial search term\n        \n        new_rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\n        old_rsi_query = rsi.keys()\n        old_rsis = rsi.values()\n        new_rsi_query = new_rsi.keys()\n        new_rsis = new_rsi.values()\n        \n        q_list = list(rsi.keys())\n        \n        for new_query in new_rsi.keys():\n            if new_query in q_list:\n                rsi[new_query] = rsi[new_query] + new_rsi[new_query]\n            else: \n                rsi[new_query] = new_rsi[new_query]\n                q_list.append(new_query)\n                \nrsi= {q: rsi[q]/30 for q in rsi.keys()}\nrsv_df['Relative Search Volume']  =  [rel_search_vol/ 30 for rel_search_vol in rsv_df['Relative Search Volume'].tolist()] \nrsv_df = rsv_df.sort_values('Relative Search Volume', ascending = False)\nrsv_df\n",
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "idx": 12,
    "time": "2021-01-28T07:04:51.861Z",
    "type": "execution"
   },
   {
    "id": "d2acb42bee8d41708cd7eb482c7603ce",
    "time": "2021-01-28T07:05:47.743Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 12,
    "time": "2021-01-28T07:09:24.994Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T07:09:25.139Z",
    "type": "completion"
   },
   {
    "code": "rsi = {d['query']:d['value'] for d in all_top_queries_rsi[initial_search_terms[0]][\"US\"]}\nrsi",
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "idx": 12,
    "time": "2021-01-28T07:10:45.874Z",
    "type": "execution"
   },
   {
    "id": "560ec8b2b1bb4b5c8f80212c1b3fdeb1",
    "time": "2021-01-28T07:10:45.992Z",
    "type": "completion"
   },
   {
    "code": "rsi_df = pd.DataFrame({\"Query\": rsi.keys(), \"Relative Search Volume\": rsi.values()})\nrsi_df",
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "idx": 14,
    "time": "2021-01-28T07:12:27.208Z",
    "type": "execution"
   },
   {
    "id": "dc053e3e4a664790a19e87b286edfef9",
    "time": "2021-01-28T07:12:27.305Z",
    "type": "completion"
   },
   {
    "code": "all_top_queries_rsi",
    "id": "6d3731db5e7b4a3882e4af700e94b10d",
    "idx": 16,
    "time": "2021-01-28T07:12:33.763Z",
    "type": "execution"
   },
   {
    "id": "6d3731db5e7b4a3882e4af700e94b10d",
    "time": "2021-01-28T07:12:33.863Z",
    "type": "completion"
   },
   {
    "code": "# RESTANDARDIZE RSI BY REMOVING DUPLICATES\n# Need to specify initial search term or origin level search term\n# Skip for level 1 queries there will be no duplicates\nall_top_queries_rsi['over the counter pill'][\"US\"]",
    "id": "f854b7a1edfc48a0943ea4e14e764e2d",
    "idx": 18,
    "time": "2021-01-28T07:12:42.094Z",
    "type": "execution"
   },
   {
    "id": "f854b7a1edfc48a0943ea4e14e764e2d",
    "time": "2021-01-28T07:12:42.205Z",
    "type": "completion"
   },
   {
    "code": "#level_log = {0: initial search term}\nlevel_log = {0:'over the counter pill/'}\n            #level.  terms etc. {(level 1 abortion pill): {term: rsv}, ... ",
    "id": "5e9d3f8094044926b2efc830c05c72ce",
    "idx": 35,
    "time": "2021-01-28T07:12:49.498Z",
    "type": "execution"
   },
   {
    "id": "5e9d3f8094044926b2efc830c05c72ce",
    "time": "2021-01-28T07:12:49.588Z",
    "type": "completion"
   },
   {
    "code": "#level_log = {0: initial search term}\nlevel_log = {0:'over the counter pill'}\n            #level.  terms etc. {(level 1 abortion pill): {term: rsv}, ... ",
    "id": "5e9d3f8094044926b2efc830c05c72ce",
    "idx": 35,
    "time": "2021-01-28T07:12:57.418Z",
    "type": "execution"
   },
   {
    "id": "5e9d3f8094044926b2efc830c05c72ce",
    "time": "2021-01-28T07:12:57.495Z",
    "type": "completion"
   },
   {
    "code": "list_of_rsi = structure_rsi_dictionary(all_top_queries_rsi['over the counter pill'][\"US\"])\nd = list_of_rsi\nd",
    "id": "fd86080b3aab477989e9c266b4cd00ff",
    "idx": 20,
    "time": "2021-01-28T07:13:25.625Z",
    "type": "execution"
   },
   {
    "id": "fd86080b3aab477989e9c266b4cd00ff",
    "time": "2021-01-28T07:13:25.715Z",
    "type": "completion"
   },
   {
    "code": "def structure_rsi_dictionary(all_top_queries_rsi_lists_of_dictionaries):\n    rsi_list = []\n    for rsi_dictionary in all_top_queries_rsi_lists_of_dictionaries:\n        dictionary = {}\n        dictionary[rsi_dictionary['query']] = rsi_dictionary['value']\n        rsi_list.append(dictionary)\n    return rsi_list",
    "id": "a1b3f61ead074f7fb6988a09e8b10078",
    "idx": 19,
    "time": "2021-01-28T07:13:29.722Z",
    "type": "execution"
   },
   {
    "id": "a1b3f61ead074f7fb6988a09e8b10078",
    "time": "2021-01-28T07:13:29.806Z",
    "type": "completion"
   },
   {
    "code": "list_of_rsi = structure_rsi_dictionary(all_top_queries_rsi['over the counter pill'][\"US\"])\nd = list_of_rsi\nd",
    "id": "fd86080b3aab477989e9c266b4cd00ff",
    "idx": 20,
    "time": "2021-01-28T07:13:30.219Z",
    "type": "execution"
   },
   {
    "id": "fd86080b3aab477989e9c266b4cd00ff",
    "time": "2021-01-28T07:13:30.374Z",
    "type": "completion"
   },
   {
    "code": "#                     running_log_of_relevant_terms_list, lst_initial_queries[initial_search_term][location]\n#d = remove_duplicates(running_log_of_relevant_terms_list, all_relative_search_volumes['abortion at home']['US'])\n#d = remove_duplicates(running_log_of_relevant_terms_list, list_of_rsi)\nd = remove_dup(running_log_of_relevant_terms_list, list_of_rsi)\nd",
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "idx": 24,
    "time": "2021-01-28T07:13:36.490Z",
    "type": "execution"
   },
   {
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "time": "2021-01-28T07:13:36.591Z",
    "type": "completion"
   },
   {
    "code": "def remove_dup(running_log_of_relevant_terms_list, list_of_rsi_dicts) :\n                    # [home abortion, etc.]      all_relative_search_volumes[initial search term]['US'] \n    unique_queries = {}\n    for dictionary in list_of_rsi_dicts:\n        query = list(dictionary.keys())[0] #ex. 'abortion pill'\n        if query not in running_log_of_relevant_terms_list:\n            running_log_of_relevant_terms_list.append(query)\n            unique_queries[query] = dictionary[query]\n    return unique_queries",
    "id": "628ae2d9d1834ecaa6e94925e5020644",
    "idx": 22,
    "time": "2021-01-28T07:13:38.411Z",
    "type": "execution"
   },
   {
    "id": "628ae2d9d1834ecaa6e94925e5020644",
    "time": "2021-01-28T07:13:38.675Z",
    "type": "completion"
   },
   {
    "code": "#                     running_log_of_relevant_terms_list, lst_initial_queries[initial_search_term][location]\n#d = remove_duplicates(running_log_of_relevant_terms_list, all_relative_search_volumes['abortion at home']['US'])\n#d = remove_duplicates(running_log_of_relevant_terms_list, list_of_rsi)\nd = remove_dup(running_log_of_relevant_terms_list, list_of_rsi)\nd",
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "idx": 24,
    "time": "2021-01-28T07:13:41.477Z",
    "type": "execution"
   },
   {
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "time": "2021-01-28T07:13:41.593Z",
    "type": "completion"
   },
   {
    "code": "#initialization at the beginning of each iteration\nrunning_log_of_relevant_terms_list = []\nrsv = []\n",
    "id": "21c16ac451d94ec79ac54bed710f8d51",
    "idx": 34,
    "time": "2021-01-28T07:13:50.432Z",
    "type": "execution"
   },
   {
    "id": "21c16ac451d94ec79ac54bed710f8d51",
    "time": "2021-01-28T07:13:50.504Z",
    "type": "completion"
   },
   {
    "code": "#                     running_log_of_relevant_terms_list, lst_initial_queries[initial_search_term][location]\n#d = remove_duplicates(running_log_of_relevant_terms_list, all_relative_search_volumes['abortion at home']['US'])\n#d = remove_duplicates(running_log_of_relevant_terms_list, list_of_rsi)\nd = remove_dup(running_log_of_relevant_terms_list, list_of_rsi)\nd",
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "idx": 24,
    "time": "2021-01-28T07:13:53.070Z",
    "type": "execution"
   },
   {
    "id": "0f20932728ba494dbd2768148cb12d8d",
    "time": "2021-01-28T07:13:53.146Z",
    "type": "completion"
   },
   {
    "code": "#Repeat for each level term\n\n# Level, initial search term, list of dictionaries with unique queries and respective rsi's\nadd_level_log(1, 'over the counter pill', d)\n#level_log[0] --> level 1 terms and level 1 term rsv\n                 # EX. {'how to do abortion': {'abortion pill': ####, etc.} }\n    \n#level_log[1] --> level 2 terms and level 2 term rsv's \n                # (ie. the relevant search terms of level 1 terms)\n                # EX. {'abortion pill': {'some term': ###, etc.} }\n",
    "id": "79195c3cd89b4dc5a12b8ebe1d07787a",
    "idx": 27,
    "time": "2021-01-28T07:14:00.756Z",
    "type": "execution"
   },
   {
    "id": "79195c3cd89b4dc5a12b8ebe1d07787a",
    "time": "2021-01-28T07:14:00.840Z",
    "type": "completion"
   },
   {
    "code": "# Log of current unique queries\nrunning_log_of_relevant_terms_list",
    "id": "7c9b1aaf3a4446c3a9e2f0dd53829ddf",
    "idx": 28,
    "time": "2021-01-28T07:14:03.772Z",
    "type": "execution"
   },
   {
    "id": "7c9b1aaf3a4446c3a9e2f0dd53829ddf",
    "time": "2021-01-28T07:14:03.864Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T07:18:15.158Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T07:18:15.267Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=''",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T07:18:19.227Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T07:18:19.313Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T07:20:09.644Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T07:20:09.745Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=''",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T08:05:52.437Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T08:05:52.533Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=AIzaSyCwrSmxtYMKbIktk0fHRFAGOfsl1t0hMSI",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T08:06:06.743Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T08:06:06.818Z",
    "type": "completion"
   },
   {
    "code": " # !!! Remove before uploading code\n%env TRENDS_DEVELOPER_KEY=''",
    "id": "cb698f0386a442e5aef959afb37cc344",
    "idx": 3,
    "time": "2021-01-28T09:08:43.938Z",
    "type": "execution"
   },
   {
    "id": "cb698f0386a442e5aef959afb37cc344",
    "time": "2021-01-28T09:08:44.009Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
